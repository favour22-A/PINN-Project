{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E: Could not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)\n",
      "E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\n",
      "E: Could not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)\n",
      "E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pypandoc\n",
      "  Downloading pypandoc-1.15-py3-none-any.whl (21 kB)\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement texlive-generic-recommended (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for texlive-generic-recommended\u001b[0m\u001b[31m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pyDOE\n",
      "  Downloading pyDOE-0.3.8.zip (22 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/lib/python3/dist-packages (from pyDOE) (1.24.2)\n",
      "Requirement already satisfied: scipy in /usr/lib/python3/dist-packages (from pyDOE) (1.10.1)\n",
      "Building wheels for collected packages: pyDOE\n",
      "  Building wheel for pyDOE (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyDOE: filename=pyDOE-0.3.8-py3-none-any.whl size=18168 sha256=a57046e6e2130d4352fbb65e7801c7aaac8ce77f2663ac1bc87656f3963eb9d1\n",
      "  Stored in directory: /home/toru/.cache/pip/wheels/84/20/8c/8bd43ba42b0b6d39ace1219d6da1576e0dac81b12265c4762e\n",
      "Successfully built pyDOE\n",
      "Installing collected packages: pyDOE\n",
      "Successfully installed pyDOE-0.3.8\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (615.4 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m615.4/615.4 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting absl-py>=1.0.0\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting flatbuffers>=24.3.25\n",
      "  Downloading flatbuffers-25.1.24-py2.py3-none-any.whl (30 kB)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1\n",
      "  Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m66.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting libclang>=13.0.0\n",
      "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/lib/python3/dist-packages (from tensorflow) (23.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/lib/python3/dist-packages (from tensorflow) (4.21.12)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/lib/python3/dist-packages (from tensorflow) (2.28.1)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorflow) (66.1.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/lib/python3/dist-packages (from tensorflow) (4.4.0)\n",
      "Collecting wrapt>=1.11.0\n",
      "  Downloading wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (83 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.2/83.2 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/lib/python3/dist-packages (from tensorflow) (1.51.1)\n",
      "Collecting tensorboard<2.19,>=2.18\n",
      "  Downloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting keras>=3.5.0\n",
      "  Downloading keras-3.8.0-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting numpy<2.1.0,>=1.26.0\n",
      "  Downloading numpy-2.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.5 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.5/19.5 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting h5py>=3.11.0\n",
      "  Downloading h5py-3.12.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.5 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting ml-dtypes<0.5.0,>=0.4.0\n",
      "  Downloading ml_dtypes-0.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
      "Collecting rich\n",
      "  Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.4/242.4 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting namex\n",
      "  Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Collecting optree\n",
      "  Downloading optree-0.14.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (405 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m405.5/405.5 kB\u001b[0m \u001b[31m343.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.3/106.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting werkzeug>=1.0.1\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/lib/python3/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (2.1.2)\n",
      "Collecting typing-extensions>=3.6.6\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/lib/python3/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.14.0)\n",
      "Collecting mdurl~=0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, werkzeug, typing-extensions, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, opt-einsum, numpy, mdurl, markdown, google-pasta, gast, astunparse, absl-py, tensorboard, optree, ml-dtypes, markdown-it-py, h5py, rich, keras, tensorflow\n",
      "\u001b[33m  WARNING: The scripts f2py and numpy-config are installed in '/home/toru/.sage/local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script markdown_py is installed in '/home/toru/.sage/local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script tensorboard is installed in '/home/toru/.sage/local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script markdown-it is installed in '/home/toru/.sage/local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The scripts import_pb_to_tensorboard, saved_model_cli, tensorboard, tf_upgrade_v2, tflite_convert, toco and toco_from_protos are installed in '/home/toru/.sage/local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "scipy 1.10.1 requires numpy<1.27.0,>=1.19.5, but you have numpy 2.0.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed absl-py-2.1.0 astunparse-1.6.3 flatbuffers-25.1.24 gast-0.6.0 google-pasta-0.2.0 h5py-3.12.1 keras-3.8.0 libclang-18.1.1 markdown-3.7 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.4.1 namex-0.0.8 numpy-2.0.2 opt-einsum-3.4.0 optree-0.14.0 rich-13.9.4 tensorboard-2.18.0 tensorboard-data-server-0.7.2 tensorflow-2.18.0 tensorflow-io-gcs-filesystem-0.37.1 termcolor-2.5.0 typing-extensions-4.12.2 werkzeug-3.1.3 wrapt-1.17.2\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: matplotlib in /usr/lib/python3/dist-packages (3.6.3)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in /home/toru/.sage/local/lib/python3.11/site-packages (2.0.2)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scipy in /usr/lib/python3/dist-packages (1.10.1)\n",
      "Collecting numpy<1.27.0,>=1.19.5\n",
      "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.0.2\n",
      "    Uninstalling numpy-2.0.2:\n",
      "      Successfully uninstalled numpy-2.0.2\n",
      "\u001b[33m  WARNING: The script f2py is installed in '/home/toru/.sage/local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed numpy-1.26.4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install pypandoc    texlive-generic-recommended --break-system-packages \n",
    "\n",
    "# Install required packages\n",
    "!pip install pyDOE --break-system-packages \n",
    "!pip install tensorflow --break-system-packages \n",
    "!pip install matplotlib --break-system-packages \n",
    "!pip install numpy --break-system-packages \n",
    "!pip install scipy --break-system-packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo apt-get install texlive-generic-recommended\n",
    "\n",
    "!sudo apt-get install texlive texlive-xetex texlive-latex-extra pandoc  texlive-generic-recommended\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W4Q9KP0QJk46"
   },
   "source": [
    "# Physics-Informed Neural Networks (PINNs) Implementation\n",
    "\n",
    "This notebook implements Physics-Informed Neural Networks (PINNs) for solving different types of differential equations:\n",
    "1. Lorenz-1960 System\n",
    "2. Harmonic Oscillator (1st and 2nd order)\n",
    "3. Hard-Constrained PINNs\n",
    "\n",
    "The implementation uses TensorFlow 2.x and is designed to run in Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZFjwxZgsJk4-",
    "outputId": "66546c32-eca4-43ab-e97b-5497ed5a1e35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyDOE in /home/toru/.sage/local/lib/python3.11/site-packages (0.3.8)\n",
      "Requirement already satisfied: numpy in /home/toru/.sage/local/lib/python3.11/site-packages (from pyDOE) (1.26.4)\n",
      "Requirement already satisfied: scipy in /usr/lib/python3/dist-packages (from pyDOE) (1.10.1)\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install pyDOE  --break-system-packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "s_-D1EanJk4_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in /home/toru/.sage/local/lib/python3.11/site-packages (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/toru/.sage/local/lib/python3.11/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/toru/.sage/local/lib/python3.11/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /home/toru/.sage/local/lib/python3.11/site-packages (from tensorflow) (25.1.24)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/toru/.sage/local/lib/python3.11/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/toru/.sage/local/lib/python3.11/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/toru/.sage/local/lib/python3.11/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/toru/.sage/local/lib/python3.11/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /usr/lib/python3/dist-packages (from tensorflow) (23.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/lib/python3/dist-packages (from tensorflow) (4.21.12)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/lib/python3/dist-packages (from tensorflow) (2.28.1)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorflow) (66.1.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/toru/.sage/local/lib/python3.11/site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/toru/.sage/local/lib/python3.11/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/toru/.sage/local/lib/python3.11/site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/lib/python3/dist-packages (from tensorflow) (1.51.1)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /home/toru/.sage/local/lib/python3.11/site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /home/toru/.sage/local/lib/python3.11/site-packages (from tensorflow) (3.8.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /home/toru/.sage/local/lib/python3.11/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /home/toru/.sage/local/lib/python3.11/site-packages (from tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /home/toru/.sage/local/lib/python3.11/site-packages (from tensorflow) (0.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/toru/.sage/local/lib/python3.11/site-packages (from tensorflow) (0.37.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: rich in /home/toru/.sage/local/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in /home/toru/.sage/local/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /home/toru/.sage/local/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow) (0.14.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/toru/.sage/local/lib/python3.11/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/toru/.sage/local/lib/python3.11/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/toru/.sage/local/lib/python3.11/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/lib/python3/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (2.1.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/toru/.sage/local/lib/python3.11/site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/lib/python3/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.14.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/toru/.sage/local/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install tensorflow --break-system-packages\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow --break-system-packages \n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pyDOE import lhs\n",
    "from scipy.integrate import solve_ivp\n",
    "import time\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(1234)\n",
    "tf.random.set_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LwmzXdoaJk5A"
   },
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YXi2x8NRJk5A"
   },
   "outputs": [],
   "source": [
    "def get_collocation_points(n_points, t_final):\n",
    "    \"\"\"Generate collocation points using Latin Hypercube Sampling\"\"\"\n",
    "    t = lhs(1, n_points).flatten()\n",
    "    t = t_final * t\n",
    "    return tf.convert_to_tensor(t, dtype=tf.float32)\n",
    "\n",
    "class LossHistory:\n",
    "    \"\"\"Track and plot training losses\"\"\"\n",
    "    def __init__(self):\n",
    "        self.total_losses = []\n",
    "        self.de_losses = []\n",
    "        self.ic_losses = []\n",
    "\n",
    "    def update(self, total_loss, de_loss, ic_loss):\n",
    "        self.total_losses.append(float(total_loss))\n",
    "        self.de_losses.append(float(de_loss))\n",
    "        self.ic_losses.append(float(ic_loss))\n",
    "\n",
    "    def plot(self):\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.semilogy(self.total_losses, label='Total Loss')\n",
    "        plt.semilogy(self.de_losses, label='DE Loss')\n",
    "        plt.semilogy(self.ic_losses, label='IC Loss')\n",
    "        plt.xlabel('Iterations')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wLaXeWkBJk5B"
   },
   "source": [
    "## Base PINN Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MhHtxdt7Jk5B"
   },
   "outputs": [],
   "source": [
    "class PINN(tf.keras.Model):\n",
    "    \"\"\"Base class for Physics-Informed Neural Networks\"\"\"\n",
    "    def __init__(self, layers, activation='tanh'):\n",
    "        super().__init__()\n",
    "        self.network_layers = []\n",
    "        for units in layers[1:-1]:\n",
    "            self.network_layers.append(tf.keras.layers.Dense(units, activation=activation))\n",
    "        self.network_layers.append(tf.keras.layers.Dense(layers[-1]))\n",
    "\n",
    "    def call(self, x):\n",
    "        for layer in self.network_layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q7wfL7vKJk5B"
   },
   "source": [
    "## Lorenz-1960 System Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "myc469Z8Jk5C"
   },
   "outputs": [],
   "source": [
    "class LorenzPINN(PINN):\n",
    "    def __init__(self, layers=[1, 20, 20, 20, 20, 3]):\n",
    "        super().__init__(layers)\n",
    "        self.k = 1.0\n",
    "        self.l = 2.0\n",
    "\n",
    "    @tf.function\n",
    "    def get_residuals(self, t):\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(t)\n",
    "            u = self(t)\n",
    "            x, y, z = tf.split(u, 3, axis=1)\n",
    "\n",
    "        du_dt = tape.gradient(u, t)\n",
    "        dx_dt, dy_dt, dz_dt = tf.split(du_dt, 3, axis=1)\n",
    "\n",
    "        k, l = self.k, self.l\n",
    "        f_x = k*l*(1.0/(k**2 + l**2) - 1.0/k**2)*y*z - dx_dt\n",
    "        f_y = k*l*(1.0/l**2 - 1.0/(k**2 + l**2))*x*z - dy_dt\n",
    "        f_z = k*l**2*(1.0/k**2 - 1.0/l**2)*x*y - dz_dt\n",
    "\n",
    "        return f_x, f_y, f_z\n",
    "\n",
    "def train_lorenz(t_final, n_points=1000, n_iter=10000):\n",
    "    # Initial conditions\n",
    "    x0, y0, z0 = 1.0, 0.5, 1.0\n",
    "\n",
    "    # Create model and optimizer\n",
    "    model = LorenzPINN()\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "    # Generate collocation points\n",
    "    t = get_collocation_points(n_points, t_final)\n",
    "    t0 = tf.zeros((1, 1), dtype=tf.float32)\n",
    "\n",
    "    history = LossHistory()\n",
    "\n",
    "    for i in range(n_iter):\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Compute residuals\n",
    "            f_x, f_y, f_z = model.get_residuals(t)\n",
    "\n",
    "            # Initial conditions loss\n",
    "            u0 = model(t0)\n",
    "            x0_pred, y0_pred, z0_pred = tf.split(u0, 3, axis=1)\n",
    "            ic_loss = tf.reduce_mean((x0_pred - x0)**2 +\n",
    "                                    (y0_pred - y0)**2 +\n",
    "                                    (z0_pred - z0)**2)\n",
    "\n",
    "            # Differential equation loss\n",
    "            de_loss = tf.reduce_mean(f_x**2 + f_y**2 + f_z**2)\n",
    "\n",
    "            # Total loss\n",
    "            loss = de_loss + ic_loss\n",
    "\n",
    "        # Gradient descent step\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            history.update(loss, de_loss, ic_loss)\n",
    "            print(f'Iteration {i}, Loss: {loss:.6f}')\n",
    "\n",
    "    history.plot()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lJuX8-6gJk5C"
   },
   "source": [
    "## Harmonic Oscillator Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1PCxuYMdJk5D"
   },
   "outputs": [],
   "source": [
    "class OscillatorPINN(PINN):\n",
    "    def __init__(self, layers=[1, 20, 20, 20, 20, 1], second_order=False):\n",
    "        super().__init__(layers)\n",
    "        self.second_order = second_order\n",
    "        self.m = 1.0\n",
    "        self.k = 2.0\n",
    "\n",
    "    @tf.function\n",
    "    def get_residuals(self, t):\n",
    "        if self.second_order:\n",
    "            with tf.GradientTape() as tape2:\n",
    "                tape2.watch(t)\n",
    "                with tf.GradientTape() as tape1:\n",
    "                    tape1.watch(t)\n",
    "                    u = self(t)\n",
    "                du_dt = tape1.gradient(u, t)\n",
    "            d2u_dt2 = tape2.gradient(du_dt, t)\n",
    "\n",
    "            return self.m * d2u_dt2 + self.k * u\n",
    "        else:\n",
    "            with tf.GradientTape() as tape:\n",
    "                tape.watch(t)\n",
    "                u = self(t)\n",
    "                x, v = tf.split(u, 2, axis=1)\n",
    "\n",
    "            du_dt = tape.gradient(u, t)\n",
    "            dx_dt, dv_dt = tf.split(du_dt, 2, axis=1)\n",
    "\n",
    "            f_x = dx_dt - v\n",
    "            f_v = dv_dt + (self.k/self.m) * x\n",
    "\n",
    "            return f_x, f_v\n",
    "\n",
    "def train_oscillator(t_final, second_order=False, n_points=1000, n_iter=10000):\n",
    "    # Initial conditions\n",
    "    x0, v0 = 1.0, 1.0\n",
    "\n",
    "    # Create model and optimizer\n",
    "    if second_order:\n",
    "        model = OscillatorPINN(layers=[1, 20, 20, 20, 20, 1], second_order=True)\n",
    "    else:\n",
    "        model = OscillatorPINN(layers=[1, 20, 20, 20, 20, 2])\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "    # Generate collocation points\n",
    "    t = get_collocation_points(n_points, t_final)\n",
    "    t0 = tf.zeros((1, 1), dtype=tf.float32)\n",
    "\n",
    "    history = LossHistory()\n",
    "\n",
    "    for i in range(n_iter):\n",
    "        with tf.GradientTape() as tape:\n",
    "            if second_order:\n",
    "                # Second order implementation\n",
    "                residual = model.get_residuals(t)\n",
    "                de_loss = tf.reduce_mean(residual**2)\n",
    "\n",
    "                # Initial conditions\n",
    "                with tf.GradientTape() as tape_ic:\n",
    "                    tape_ic.watch(t0)\n",
    "                    u0 = model(t0)\n",
    "                du0_dt = tape_ic.gradient(u0, t0)\n",
    "\n",
    "                ic_loss = tf.reduce_mean((u0 - x0)**2 + (du0_dt - v0)**2)\n",
    "            else:\n",
    "                # First order system implementation\n",
    "                f_x, f_v = model.get_residuals(t)\n",
    "                de_loss = tf.reduce_mean(f_x**2 + f_v**2)\n",
    "\n",
    "                # Initial conditions\n",
    "                u0 = model(t0)\n",
    "                x0_pred, v0_pred = tf.split(u0, 2, axis=1)\n",
    "                ic_loss = tf.reduce_mean((x0_pred - x0)**2 + (v0_pred - v0)**2)\n",
    "\n",
    "            # Total loss\n",
    "            loss = de_loss + ic_loss\n",
    "\n",
    "        # Gradient descent step\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            history.update(loss, de_loss, ic_loss)\n",
    "            print(f'Iteration {i}, Loss: {loss:.6f}')\n",
    "\n",
    "    history.plot()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NX2rbYQSJk5D"
   },
   "source": [
    "## Hard-Constrained PINN Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gg0TiBMCJk5D"
   },
   "outputs": [],
   "source": [
    "class HardConstrainedPINN(PINN):\n",
    "    \"\"\"Hard-constrained Physics-Informed Neural Network\"\"\"\n",
    "    def __init__(self, layers=[1, 20, 20, 20, 20, 3], initial_conditions=None):\n",
    "        super().__init__(layers)\n",
    "        self.initial_conditions = initial_conditions or {}\n",
    "\n",
    "    def call(self, t):\n",
    "        # Base network output\n",
    "        N = super().call(t)\n",
    "\n",
    "        # Apply hard constraints using t·N(t) formulation\n",
    "        outputs = []\n",
    "        for i, (name, ic) in enumerate(self.initial_conditions.items()):\n",
    "            y = ic + t * N[:, i:i+1]\n",
    "            outputs.append(y)\n",
    "\n",
    "        return tf.concat(outputs, axis=1)\n",
    "\n",
    "class TaylorHardConstrainedPINN(PINN):\n",
    "    \"\"\"Second-order Taylor expansion based hard-constrained PINN\"\"\"\n",
    "    def __init__(self, layers=[1, 20, 20, 20, 20, 1], u0=0.0, v0=0.0):\n",
    "        super().__init__(layers)\n",
    "        self.u0 = u0\n",
    "        self.v0 = v0\n",
    "\n",
    "    def call(self, t):\n",
    "        # Base network output\n",
    "        N = super().call(t)\n",
    "\n",
    "        # Second-order Taylor expansion\n",
    "        y = self.u0 + self.v0 * t + t**2 * N\n",
    "        return y\n",
    "\n",
    "def train_hard_constrained_lorenz(t_final, n_points=1000, n_iter=10000):\n",
    "    x0, y0, z0 = 1.0, 0.5, 1.0\n",
    "\n",
    "    # Create model with hard constraints\n",
    "    model = HardConstrainedPINN(initial_conditions={'x': x0, 'y': y0, 'z': z0})\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "    # Generate collocation points\n",
    "    t = get_collocation_points(n_points, t_final)\n",
    "\n",
    "    history = LossHistory()\n",
    "\n",
    "    for i in range(n_iter):\n",
    "        with tf.GradientTape() as tape:\n",
    "            f_x, f_y, f_z = model.get_residuals(t)\n",
    "            de_loss = tf.reduce_mean(f_x**2 + f_y**2 + f_z**2)\n",
    "            loss = de_loss  # No IC loss needed for hard constraints\n",
    "\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            history.update(loss, de_loss, 0.0)\n",
    "            print(f'Iteration {i}, Loss: {loss:.6f}')\n",
    "\n",
    "    history.plot()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8HGGS_cGJk5E"
   },
   "source": [
    "## Example Usage and Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 685
    },
    "id": "syyB-1OvJk5E",
    "outputId": "dba03d0c-3d75-41c0-bbe5-a478a55920cc"
   },
   "outputs": [],
   "source": [
    "# Compare different integration times for Lorenz system\n",
    "tf_values = [1, 5, 10, 20]\n",
    "results = {}\n",
    "\n",
    "for tfval in tf_values:\n",
    "    print(f'\\nTraining for tf = {tfval }')\n",
    "    # Train soft-constrained PINN\n",
    "    model_soft = train_lorenz(tfval )\n",
    "\n",
    "    # Train hard-constrained PINN\n",
    "    model_hard = train_hard_constrained_lorenz(tfval )\n",
    "\n",
    "    # Classical solver (reference solution)\n",
    "    def lorenz_system(t, y):\n",
    "        x, y, z = y\n",
    "        k, l = 1.0, 2.0\n",
    "        dx = k*l*(1.0/(k**2 + l**2) - 1.0/k**2)*y*z\n",
    "        dy = k*l*(1.0/l**2 - 1.0/(k**2 + l**2))*x*z\n",
    "        dz = k*l**2*(1.0/k**2 - 1.0/l**2)*x*y\n",
    "        return [dx, dy, dz]\n",
    "\n",
    "    sol = solve_ivp(lorenz_system, [0, tf], [1.0, 0.5, 1.0],\n",
    "                   method='RK45', rtol=1e-8, atol=1e-8)\n",
    "\n",
    "    # Evaluate solutions on uniform grid\n",
    "    t_eval = np.linspace(0, tf, 1000).reshape(-1, 1)\n",
    "    t_eval_tf = tf.convert_to_tensor(t_eval, dtype=tf.float32)\n",
    "\n",
    "    y_soft = model_soft(t_eval_tf).numpy()\n",
    "    y_hard = model_hard(t_eval_tf).numpy()\n",
    "\n",
    "    results[tf] = {\n",
    "        't': t_eval,\n",
    "        'soft': y_soft,\n",
    "        'hard': y_hard,\n",
    "        'classical': np.array([np.interp(t_eval.flatten(), sol.t, sol.y[i])\n",
    "                              for i in range(3)]).T\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EeXcejAHN7Uf"
   },
   "outputs": [],
   "source": [
    "def get_collocation_points(n_points, t_final):\n",
    "    \"\"\"Generate collocation points using Latin Hypercube Sampling\"\"\"\n",
    "    t = lhs(1, n_points).flatten()\n",
    "    t = t_final * t\n",
    "    # Reshape t to have an extra dimension for the batch size\n",
    "    t = t.reshape(-1, 1)  # Reshape to (n_points, 1)\n",
    "    return tf.convert_to_tensor(t, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L_F9T2-KLe0x"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from scipy.integrate import solve_ivp\n",
    "\n",
    "# Compare different integration times for Lorenz system\n",
    "tf_values = [1, 5, 10, 20]\n",
    "results = {}\n",
    "\n",
    "for t_final in tf_values:  # Renamed tfval to t_final to avoid conflicts\n",
    "    print(f'\\nTraining for tf = {t_final}')\n",
    "\n",
    "    # Train soft-constrained PINN\n",
    "    model_soft = train_lorenz(t_final)\n",
    "\n",
    "    # Train hard-constrained PINN\n",
    "    model_hard = train_hard_constrained_lorenz(t_final)\n",
    "\n",
    "    # Classical solver (reference solution)\n",
    "    def lorenz_system(t, y):\n",
    "        x, y, z = y\n",
    "        k, l = 1.0, 2.0\n",
    "        dx = k * l * (1.0 / (k**2 + l**2) - 1.0 / k**2) * y * z\n",
    "        dy = k * l * (1.0 / l**2 - 1.0 / (k**2 + l**2)) * x * z\n",
    "        dz = k * l**2 * (1.0 / k**2 - 1.0 / l**2) * x * y\n",
    "        return [dx, dy, dz]\n",
    "\n",
    "    sol = solve_ivp(lorenz_system, [0, t_final], [1.0, 0.5, 1.0],\n",
    "                    method='RK45', rtol=1e-8, atol=1e-8)\n",
    "\n",
    "    # Evaluate solutions on uniform grid\n",
    "    t_eval = np.linspace(0, t_final, 1000).reshape(-1, 1)\n",
    "    t_eval_tf = tf.convert_to_tensor(t_eval, dtype=tf.float32)  # Ensure tf is TensorFlow\n",
    "\n",
    "    y_soft = model_soft(t_eval_tf).numpy()\n",
    "    y_hard = model_hard(t_eval_tf).numpy()\n",
    "\n",
    "    results[t_final] = {\n",
    "        't': t_eval,\n",
    "        'soft': y_soft,\n",
    "        'hard': y_hard,\n",
    "        'classical': np.array([np.interp(t_eval.flatten(), sol.t, sol.y[i])\n",
    "                               for i in range(3)]).T\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F2caGtcRJk5E"
   },
   "outputs": [],
   "source": [
    "# Visualization of results\n",
    "def plot_comparison(tf):\n",
    "    res = results[tf]\n",
    "    fig = plt.figure(figsize=(15, 5))\n",
    "    titles = ['x(t)', 'y(t)', 'z(t)']\n",
    "\n",
    "    for i in range(3):\n",
    "        plt.subplot(1, 3, i+1)\n",
    "        plt.plot(res['t'], res['classical'][:, i], 'k-', label='Classical')\n",
    "        plt.plot(res['t'], res['soft'][:, i], 'r--', label='Soft PINN')\n",
    "        plt.plot(res['t'], res['hard'][:, i], 'b:', label='Hard PINN')\n",
    "        plt.xlabel('t')\n",
    "        plt.ylabel(titles[i])\n",
    "        plt.title(f'{titles[i]} (tf={tf})')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot results for each tf\n",
    "for tf in tf_values:\n",
    "    plot_comparison(tf)\n",
    "\n",
    "# Compute and display errors\n",
    "for tf in tf_values:\n",
    "    res = results[tf]\n",
    "    err_soft = np.mean((res['soft'] - res['classical'])**2)\n",
    "    err_hard = np.mean((res['hard'] - res['classical'])**2)\n",
    "    print(f'\\nMean squared error for tf={tf}:')\n",
    "    print(f'Soft PINN: {err_soft:.2e}')\n",
    "    print(f'Hard PINN: {err_hard:.2e}')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
